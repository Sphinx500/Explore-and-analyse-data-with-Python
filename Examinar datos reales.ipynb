{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNTUlT0rZ9rEs6OERmi9pl6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sphinx500/Explore-and-analyse-data-with-Python/blob/main/Examinar%20datos%20reales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOhl7eJlZuDK"
      },
      "source": [
        "## Examinar datos del mundo real"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9Sf2YZmZxKt"
      },
      "source": [
        "Los datos presentados en el material educativo suelen ser notablemente perfectos y están diseñados para mostrar a los estudiantes cómo encontrar relaciones claras entre las variables. Los datos del \"mundo real\" son un poco menos simples.\n",
        "\n",
        "Debido a la complejidad de los datos del \"mundo real\", los datos sin procesar deben inspeccionarse para detectar problemas antes de usarlos.\n",
        "\n",
        "Como tal, la mejor práctica es inspeccionar los datos sin procesar y procesarlos antes de usarlos, lo que reduce los errores o problemas, generalmente eliminando puntos de datos erróneos o modificando los datos en una forma más útil."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5kt9WdRZ1uB"
      },
      "source": [
        "**Problemas de datos del mundo real**\n",
        "\n",
        "Los datos del mundo real pueden contener muchos problemas diferentes que pueden afectar la utilidad de los datos y nuestra interpretación de los resultados.\n",
        "\n",
        "Es importante darse cuenta de que la mayoría de los datos del mundo real están influenciados por factores que no se registraron en ese momento. Por ejemplo, podríamos tener una tabla de tiempos de pista de autos de carrera junto con los tamaños de los motores, pero varios otros factores que no se anotaron, como el clima, probablemente también influyeron. Si es problemático, la influencia de estos factores a menudo se puede reducir aumentando el tamaño del conjunto de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_pdycWCZ5R5"
      },
      "source": [
        "En otras situaciones, los puntos de datos que están claramente fuera de lo esperado, también conocidos como \"valores atípicos\", a veces se pueden eliminar de forma segura de los análisis, aunque se debe tener cuidado de no eliminar los puntos de datos que brindan información real.\n",
        "\n",
        "Otro problema común en los datos del mundo real es el sesgo. El sesgo se refiere a una tendencia a seleccionar ciertos tipos de valores con más frecuencia que otros, de una manera que tergiversa la población subyacente o el \"mundo real\". A veces, el sesgo se puede identificar mediante la exploración de datos teniendo en cuenta los conocimientos básicos sobre el origen de los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ncG_RoSaAwN"
      },
      "source": [
        "Recuerde, los datos del mundo real siempre tendrán problemas, pero este suele ser un problema superable. Recuerda:\n",
        "\n",
        "* Compruebe si faltan valores y datos mal registrados\n",
        "* Considere la eliminación de valores atípicos obvios\n",
        "* Considere qué factores del mundo real podrían afectar su análisis y considere si el tamaño de su conjunto de datos es lo suficientemente grande para manejar esto\n",
        "* Compruebe si hay datos brutos sesgados y considere sus opciones para solucionar este problema, si se encuentran"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjtF04HQaIKM"
      },
      "source": [
        "## Ejercicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QUnGN0MaJ7l"
      },
      "source": [
        "La última vez, analizamos las calificaciones de los datos de nuestros estudiantes y lo investigamos visualmente con histogramas y diagramas de caja. Ahora veremos casos más complejos, describiremos los datos de manera más completa y discutiremos cómo hacer comparaciones básicas entre los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1b8Af8saTPr"
      },
      "source": [
        "Distribuciones de datos del mundo real\n",
        "La última vez, analizamos las calificaciones de los datos de nuestros estudiantes y estimamos a partir de esta muestra cómo se vería la población completa de calificaciones. Solo para actualizar, echemos un vistazo a estos datos nuevamente.\n",
        "\n",
        "Ejecute el siguiente código para imprimir los datos y hacer un histograma + diagrama de caja que muestre las calificaciones de nuestra muestra de estudiantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lq-ImanaWE8"
      },
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Load data from a text file\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/grades.csv\n",
        "df_students = pd.read_csv('grades.csv',delimiter=',',header='infer')\n",
        "\n",
        "# Remove any rows with missing data\n",
        "df_students = df_students.dropna(axis=0, how='any')\n",
        "\n",
        "# Calculate who passed, assuming '60' is the grade needed to pass\n",
        "passes  = pd.Series(df_students['Grade'] >= 60)\n",
        "\n",
        "# Save who passed to the Pandas dataframe\n",
        "df_students = pd.concat([df_students, passes.rename(\"Pass\")], axis=1)\n",
        "\n",
        "\n",
        "# Print the result out into this notebook\n",
        "print(df_students)\n",
        "\n",
        "\n",
        "# Create a function that we can re-use\n",
        "def show_distribution(var_data):\n",
        "    '''\n",
        "    This function will make a distribution (graph) and display it\n",
        "    '''\n",
        "\n",
        "    # Get statistics\n",
        "    min_val = var_data.min()\n",
        "    max_val = var_data.max()\n",
        "    mean_val = var_data.mean()\n",
        "    med_val = var_data.median()\n",
        "    mod_val = var_data.mode()[0]\n",
        "\n",
        "    print('Minimum:{:.2f}\\nMean:{:.2f}\\nMedian:{:.2f}\\nMode:{:.2f}\\nMaximum:{:.2f}\\n'.format(min_val,\n",
        "                                                                                            mean_val,\n",
        "                                                                                            med_val,\n",
        "                                                                                            mod_val,\n",
        "                                                                                            max_val))\n",
        "\n",
        "    # Create a figure for 2 subplots (2 rows, 1 column)\n",
        "    fig, ax = plt.subplots(2, 1, figsize = (10,4))\n",
        "\n",
        "    # Plot the histogram   \n",
        "    ax[0].hist(var_data)\n",
        "    ax[0].set_ylabel('Frequency')\n",
        "\n",
        "    # Add lines for the mean, median, and mode\n",
        "    ax[0].axvline(x=min_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
        "    ax[0].axvline(x=mean_val, color = 'cyan', linestyle='dashed', linewidth = 2)\n",
        "    ax[0].axvline(x=med_val, color = 'red', linestyle='dashed', linewidth = 2)\n",
        "    ax[0].axvline(x=mod_val, color = 'yellow', linestyle='dashed', linewidth = 2)\n",
        "    ax[0].axvline(x=max_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
        "\n",
        "    # Plot the boxplot   \n",
        "    ax[1].boxplot(var_data, vert=False)\n",
        "    ax[1].set_xlabel('Value')\n",
        "\n",
        "    # Add a title to the Figure\n",
        "    fig.suptitle('Data Distribution')\n",
        "\n",
        "    # Show the figure\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "show_distribution(df_students['Grade'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-47Ffe4aYmz"
      },
      "source": [
        "Como recordará, nuestros datos tenían la media y la moda en el centro, con datos distribuidos simétricamente desde allí.\n",
        "\n",
        "Ahora echemos un vistazo a la distribución de los datos de las horas de estudio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klz7tGJxaaiM"
      },
      "source": [
        "# Get the variable to examine\n",
        "col = df_students['StudyHours']\n",
        "# Call the function\n",
        "show_distribution(col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1ul3dVeabEM"
      },
      "source": [
        "La distribución de los datos del tiempo de estudio es significativamente diferente a la de los grados.\n",
        "\n",
        "Tenga en cuenta que los bigotes del diagrama de caja solo comienzan alrededor de 6.0, lo que indica que la gran mayoría del primer trimestre de los datos está por encima de este valor. El mínimo está marcado con una o, lo que indica que es estadísticamente un valor atípico, un valor que se encuentra significativamente fuera del rango del resto de la distribución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98lG-dqYae9c"
      },
      "source": [
        "Los valores atípicos pueden ocurrir por muchas razones. Tal vez un estudiante tenía la intención de registrar \"10\" horas de tiempo de estudio, pero ingresó \"1\" y perdió el \"0\". ¡O tal vez el estudiante era anormalmente perezoso cuando se trata de estudiar! De cualquier manera, es una anomalía estadística que no representa a un estudiante típico. Veamos cómo se ve la distribución sin él."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwm-WejXajbi"
      },
      "source": [
        "# Get the variable to examine\n",
        "# We will only get students who have studied more than one hour\n",
        "col = df_students[df_students.StudyHours>1]['StudyHours']\n",
        "\n",
        "# Call the function\n",
        "show_distribution(col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-UONoN0amYE"
      },
      "source": [
        "Para fines de aprendizaje, acabamos de tratar que el valor 1 es un valor atípico y lo excluimos. En el mundo real, sin embargo, sería inusual excluir datos en los extremos sin más justificación cuando el tamaño de nuestra muestra es tan pequeño. Esto se debe a que cuanto menor sea el tamaño de nuestra muestra, más probable es que nuestra muestra sea una mala representación de toda la población (aquí, la población significa calificaciones para todos los estudiantes, no solo para nuestros 22). Por ejemplo, si tomamos una muestra del tiempo de estudio de otros 1000 estudiantes, ¡podríamos encontrar que en realidad es bastante común no estudiar mucho!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP7Vck9-aoLD"
      },
      "source": [
        "When we have more data available, our sample becomes more reliable. This makes it easier to consider outliers as being values that fall below or above percentiles within which most of the data lie. For example, the following code uses the Pandas quantile function to exclude observations below the 0.01th percentile (the value above which 99% of the data reside)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vexhRqycapNt"
      },
      "source": [
        "# calculate the 0.01th percentile\n",
        "q01 = df_students.StudyHours.quantile(0.01)\n",
        "# Get the variable to examine\n",
        "col = df_students[df_students.StudyHours>q01]['StudyHours']\n",
        "# Call the function\n",
        "show_distribution(col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i_ZNS_ecYvG"
      },
      "source": [
        "Con los valores atípicos eliminados, el diagrama de caja muestra todos los datos dentro de los cuatro cuartiles. Sin embargo, tenga en cuenta que la distribución no es simétrica como lo es para los datos de calificaciones: hay algunos estudiantes con tiempos de estudio muy altos de alrededor de 16 horas, pero la mayor parte de los datos está entre 7 y 13 horas; Los pocos valores extremadamente altos empujan la media hacia el extremo superior de la escala.\n",
        "\n",
        "Veamos la densidad de esta distribución."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-b82ZGIcbS4"
      },
      "source": [
        "def show_density(var_data):\n",
        "    fig = plt.figure(figsize=(10,4))\n",
        "\n",
        "    # Plot density\n",
        "    var_data.plot.density()\n",
        "\n",
        "    # Add titles and labels\n",
        "    plt.title('Data Density')\n",
        "\n",
        "    # Show the mean, median, and mode\n",
        "    plt.axvline(x=var_data.mean(), color = 'cyan', linestyle='dashed', linewidth = 2)\n",
        "    plt.axvline(x=var_data.median(), color = 'red', linestyle='dashed', linewidth = 2)\n",
        "    plt.axvline(x=var_data.mode()[0], color = 'yellow', linestyle='dashed', linewidth = 2)\n",
        "\n",
        "    # Show the figure\n",
        "    plt.show()\n",
        "\n",
        "# Get the density of StudyHours\n",
        "show_density(col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFV1ipArcard"
      },
      "source": [
        "Este tipo de distribución se llama sesgada a la derecha. La masa de los datos está en el lado izquierdo de la distribución, creando una cola larga a la derecha debido a los valores en el extremo superior; que tiran de la media hacia la derecha."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h90Hr4fJcguZ"
      },
      "source": [
        "**Medidas de varianza**\n",
        "\n",
        "Así que ahora tenemos una buena idea de dónde están las distribuciones de datos de la mitad de la calificación y las horas de estudio. Sin embargo, hay otro aspecto de las distribuciones que deberíamos examinar: ¿cuánta variabilidad hay en los datos?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91_81BZLclzX"
      },
      "source": [
        "Las estadísticas típicas que miden la variabilidad en los datos incluyen:\n",
        "\n",
        "* Rango: la diferencia entre el máximo y el mínimo. No hay una función incorporada para esto, pero es fácil de calcular usando las funciones mín. Y máx.\n",
        "* Varianza: el promedio de la diferencia al cuadrado de la media. Puede usar la función var incorporada para encontrar esto.\n",
        "* Desviación estándar: la raíz cuadrada de la varianza. Puede usar la función estándar incorporada para encontrar esto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD6shkducq5g"
      },
      "source": [
        "for col_name in ['Grade','StudyHours']:\n",
        "    col = df_students[col_name]\n",
        "    rng = col.max() - col.min()\n",
        "    var = col.var()\n",
        "    std = col.std()\n",
        "    print('\\n{}:\\n - Range: {:.2f}\\n - Variance: {:.2f}\\n - Std.Dev: {:.2f}'.format(col_name, rng, var, std))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS700bF8cuCN"
      },
      "source": [
        "De estas estadísticas, la desviación estándar es generalmente la más útil. Proporciona una medida de la varianza de los datos en la misma escala que los propios datos (por lo tanto, puntos de calificación para la distribución de calificaciones y horas para la distribución de horas de estudio). Cuanto mayor es la desviación estándar, mayor es la varianza cuando se comparan los valores de la distribución con la media de la distribución; en otras palabras, los datos están más dispersos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEr1zfXVcwkQ"
      },
      "source": [
        "Cuando se trabaja con una distribución normal, la desviación estándar trabaja con las características particulares de una distribución normal para proporcionar una comprensión aún mayor. Ejecute la celda a continuación para ver la relación entre las desviaciones estándar y los datos en la distribución normal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzpcyP3acyrv"
      },
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Get the Grade column\n",
        "col = df_students['Grade']\n",
        "\n",
        "# get the density\n",
        "density = stats.gaussian_kde(col)\n",
        "\n",
        "# Plot the density\n",
        "col.plot.density()\n",
        "\n",
        "# Get the mean and standard deviation\n",
        "s = col.std()\n",
        "m = col.mean()\n",
        "\n",
        "# Annotate 1 stdev\n",
        "x1 = [m-s, m+s]\n",
        "y1 = density(x1)\n",
        "plt.plot(x1,y1, color='magenta')\n",
        "plt.annotate('1 std (68.26%)', (x1[1],y1[1]))\n",
        "\n",
        "# Annotate 2 stdevs\n",
        "x2 = [m-(s*2), m+(s*2)]\n",
        "y2 = density(x2)\n",
        "plt.plot(x2,y2, color='green')\n",
        "plt.annotate('2 std (95.45%)', (x2[1],y2[1]))\n",
        "\n",
        "# Annotate 3 stdevs\n",
        "x3 = [m-(s*3), m+(s*3)]\n",
        "y3 = density(x3)\n",
        "plt.plot(x3,y3, color='orange')\n",
        "plt.annotate('3 std (99.73%)', (x3[1],y3[1]))\n",
        "\n",
        "# Show the location of the mean\n",
        "plt.axvline(col.mean(), color='cyan', linestyle='dashed', linewidth=1)\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYFXGwgkc1na"
      },
      "source": [
        "Las líneas horizontales muestran el porcentaje de datos dentro de 1, 2 y 3 desviaciones estándar de la media (más o menos).\n",
        "\n",
        "En cualquier distribución normal:\n",
        "\n",
        "* Aproximadamente el 68,26% de los valores se encuentran dentro de una desviación estándar de la media.\n",
        "* Aproximadamente el 95,45% de los valores se encuentran dentro de dos desviaciones estándar de la media.\n",
        "* Aproximadamente el 99,73% de los valores se encuentran dentro de tres desviaciones estándar de la media."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hiv1qnoc7CY"
      },
      "source": [
        "Entonces, como sabemos que la nota media es 49,18, la desviación estándar es 21,74 y la distribución de las notas es aproximadamente normal; podemos calcular que el 68,26% de los alumnos debería alcanzar una nota entre 27,44 y 70,92.\n",
        "\n",
        "Las estadísticas descriptivas que hemos utilizado para comprender la distribución de las variables de datos de los estudiantes son la base del análisis estadístico; y debido a que son una parte tan importante de la exploración de sus datos, hay un método Describe incorporado del objeto DataFrame que devuelve las principales estadísticas descriptivas para todas las columnas numéricas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqb-ghhvdDj4"
      },
      "source": [
        "df_students.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeFqhrYAdRu-"
      },
      "source": [
        "**Comparando datos**\n",
        "\n",
        "Ahora que sabe algo sobre la distribución estadística de los datos en su conjunto de datos, está listo para examinar sus datos para identificar cualquier relación aparente entre las variables.\n",
        "\n",
        "En primer lugar, eliminemos las filas que contengan valores atípicos para tener una muestra que sea representativa de una clase típica de estudiantes. Identificamos que la columna StudyHours contiene algunos valores atípicos con valores extremadamente bajos, por lo que eliminaremos esas filas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2onrlPT3dU8U"
      },
      "source": [
        "df_sample = df_students[df_students['StudyHours']>1]\n",
        "df_sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL4CzkI0dYlF"
      },
      "source": [
        "**Comparación de variables numéricas y categóricas**\n",
        "\n",
        "Los datos incluyen dos variables numéricas (StudyHours y Grade) y dos variables categóricas (Name y Pass). Comencemos comparando la columna numérica StudyHours con la columna categórica Aprobado para ver si existe una relación aparente entre la cantidad de horas estudiadas y una calificación aprobatoria.\n",
        "\n",
        "Para hacer esta comparación, creemos diagramas de caja que muestren la distribución de StudyHours para cada posible valor de Aprobación (verdadero y falso)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlN4Nenvdcb3"
      },
      "source": [
        "df_sample.boxplot(column='StudyHours', by='Pass', figsize=(8,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdaW1Eypdfnu"
      },
      "source": [
        "Al comparar las distribuciones de StudyHours, es inmediatamente evidente (si no particularmente sorprendente) que los estudiantes que aprobaron el curso tendieron a estudiar más horas que los estudiantes que no lo hicieron. Entonces, si desea predecir si es probable que un estudiante apruebe o no el curso, la cantidad de tiempo que pasa estudiando puede ser una buena característica de predicción."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUPGgADjdhS4"
      },
      "source": [
        "**Comparar variables numéricas**\n",
        "\n",
        "Ahora comparemos dos variables numéricas. Comenzaremos creando un gráfico de barras que muestre las calificaciones y las horas de estudio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "355z8GEodoRd"
      },
      "source": [
        "# Create a bar plot of name vs grade and study hours\n",
        "df_sample.plot(x='Name', y=['Grade','StudyHours'], kind='bar', figsize=(8,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns8g6mBndrHf"
      },
      "source": [
        "El gráfico muestra barras para el grado y las horas de estudio de cada estudiante; pero no es fácil de comparar porque los valores están en diferentes escalas. Las calificaciones se miden en puntos de calificación y varían de 3 a 97; mientras que el tiempo de estudio se mide en horas y varía de 1 a 16.\n",
        "\n",
        "Una técnica común cuando se trabaja con datos numéricos en diferentes escalas es normalizar los datos para que los valores mantengan su distribución proporcional, pero se midan en la misma escala. Para lograr esto, usaremos una técnica llamada escala MinMax que distribuye los valores proporcionalmente en una escala de 0 a 1. Puede escribir el código para aplicar esta transformación; pero la biblioteca Scikit-Learn proporciona un escalador para que lo haga por usted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsNMDqKGdsxt"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Get a scaler object\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Create a new dataframe for the scaled values\n",
        "df_normalized = df_sample[['Name', 'Grade', 'StudyHours']].copy()\n",
        "\n",
        "# Normalize the numeric columns\n",
        "df_normalized[['Grade','StudyHours']] = scaler.fit_transform(df_normalized[['Grade','StudyHours']])\n",
        "\n",
        "# Plot the normalized values\n",
        "df_normalized.plot(x='Name', y=['Grade','StudyHours'], kind='bar', figsize=(8,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg637NW8dvLW"
      },
      "source": [
        "Con los datos normalizados, es más fácil ver una relación aparente entre la calificación y el tiempo de estudio. No es una coincidencia exacta, pero definitivamente parece que los estudiantes con calificaciones más altas tienden a haber estudiado más.\n",
        "\n",
        "Entonces parece haber una correlación entre el tiempo de estudio y la calificación; y de hecho, existe una medida de correlación estadística que podemos utilizar para cuantificar la relación entre estas columnas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBH9ZnmldzgC"
      },
      "source": [
        "df_normalized.Grade.corr(df_normalized.StudyHours)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5_RNOi8d3G-"
      },
      "source": [
        "La estadística de correlación es un valor entre -1 y 1 que indica la fuerza de una relación. Los valores por encima de 0 indican una correlación positiva (los valores altos de una variable tienden a coincidir con los valores altos de la otra), mientras que los valores por debajo de 0 indican una correlación negativa (los valores altos de una variable tienden a coincidir con los valores bajos de la otra). En este caso, el valor de correlación es cercano a 1; mostrando una correlación fuertemente positiva entre el tiempo de estudio y el grado.\n",
        "\n",
        "Otra forma de visualizar la aparente correlación entre dos columnas numéricas es usar un diagrama de dispersión."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhwHrguEd79t"
      },
      "source": [
        "# Create a scatter plot\n",
        "df_sample.plot.scatter(title='Study Time vs Grade', x='StudyHours', y='Grade')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bkr261cEd_Ng"
      },
      "source": [
        "Nuevamente, parece que hay un patrón discernible en el que los estudiantes que estudiaron más horas son también los estudiantes que obtuvieron las calificaciones más altas.\n",
        "\n",
        "Podemos ver esto más claramente agregando una línea de regresión (o una línea de mejor ajuste) al gráfico que muestra la tendencia general en los datos. Para hacer esto, usaremos una técnica estadística llamada regresión de mínimos cuadrados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1VAJbKxeCLO"
      },
      "source": [
        "Afortunadamente, no necesita codificar el cálculo de regresión usted mismo: el paquete SciPy incluye una clase de estadísticas que proporciona un método linregress para hacer el trabajo duro por usted. Esto devuelve (entre otras cosas) los coeficientes que necesita para la ecuación de pendiente: pendiente (m) e intersección (b) en función de un par de muestras variables que desea comparar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu2nCnKseD1V"
      },
      "source": [
        "from scipy import stats\n",
        "\n",
        "#\n",
        "df_regression = df_sample[['Grade', 'StudyHours']].copy()\n",
        "\n",
        "# Get the regression slope and intercept\n",
        "m, b, r, p, se = stats.linregress(df_regression['StudyHours'], df_regression['Grade'])\n",
        "print('slope: {:.4f}\\ny-intercept: {:.4f}'.format(m,b))\n",
        "print('so...\\n f(x) = {:.4f}x + {:.4f}'.format(m,b))\n",
        "\n",
        "# Use the function (mx + b) to calculate f(x) for each x (StudyHours) value\n",
        "df_regression['fx'] = (m * df_regression['StudyHours']) + b\n",
        "\n",
        "# Calculate the error between f(x) and the actual y (Grade) value\n",
        "df_regression['error'] = df_regression['fx'] - df_regression['Grade']\n",
        "\n",
        "# Create a scatter plot of Grade vs Salary\n",
        "df_regression.plot.scatter(x='StudyHours', y='Grade')\n",
        "\n",
        "# Plot the regression line\n",
        "plt.plot(df_regression['StudyHours'],df_regression['fx'], color='cyan')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8Y84cGEeGrl"
      },
      "source": [
        "Tenga en cuenta que esta vez, el código trazó dos cosas distintas: el diagrama de dispersión de las horas de estudio de muestra y las calificaciones se trazan como antes, y luego se traza una línea de mejor ajuste basada en los coeficientes de regresión de mínimos cuadrados.\n",
        "\n",
        "Los coeficientes de pendiente e intersección calculados para la línea de regresión se muestran encima del gráfico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mco8C7ZNeLWx"
      },
      "source": [
        "La línea se basa en los valores f (x) calculados para cada valor de StudyHours. Ejecute la siguiente celda para ver una tabla que incluye los siguientes valores:\n",
        "\n",
        "* Las horas de estudio para cada alumno.\n",
        "* La nota obtenida por cada alumno.\n",
        "* El valor de f (x) calculado utilizando los coeficientes de la línea de regresión.\n",
        "* El error entre el valor calculado de f (x) y el valor real de la calificación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CjcGW9BeQeA"
      },
      "source": [
        "Algunos de los errores, particularmente en los extremos, y bastante grandes (hasta más de 17,5 puntos); pero en general, la línea se acerca bastante a las calificaciones reales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ipz3GzUjeSYC"
      },
      "source": [
        "# Show the original x,y values, the f(x) value, and the error\n",
        "df_regression[['StudyHours', 'Grade', 'fx', 'error']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBaxfQwQeTsX"
      },
      "source": [
        "\n",
        "**Usando los coeficientes de regresión para la predicción**\n",
        "\n",
        "Ahora que tiene los coeficientes de regresión para el tiempo de estudio y la relación de calificaciones, puede usarlos en una función para estimar la calificación esperada para una determinada cantidad de estudio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwkJVa4SecjM"
      },
      "source": [
        "# Define a function based on our regression coefficients\n",
        "def f(x):\n",
        "    m = 6.3134\n",
        "    b = -17.9164\n",
        "    return m*x + b\n",
        "\n",
        "study_time = 14\n",
        "\n",
        "# Get f(x) for study time\n",
        "prediction = f(study_time)\n",
        "\n",
        "# Grade can't be less than 0 or more than 100\n",
        "expected_grade = max(0,min(100,prediction))\n",
        "\n",
        "#Print the estimated grade\n",
        "print ('Studying for {} hours per week may result in a grade of {:.0f}'.format(study_time, expected_grade))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtlPXX_HegMR"
      },
      "source": [
        "Entonces, al aplicar estadísticas a los datos de muestra, ha determinado una relación entre el tiempo de estudio y la calificación; y encapsuló esa relación en una función general que puede usarse para predecir una calificación para una cantidad determinada de tiempo de estudio.\n",
        "\n",
        "Esta técnica es, de hecho, la premisa básica del aprendizaje automático. Puede tomar un conjunto de datos de muestra que incluye una o más características (en este caso, la cantidad de horas estudiadas) y un valor de etiqueta conocido (en este caso, la calificación obtenida) y usar los datos de muestra para derivar una función que calcule valores de etiqueta predichos para cualquier conjunto de características dado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_FbASy5ejjX"
      },
      "source": [
        "**Resumen**\n",
        "Aquí hemos visto:\n",
        "\n",
        "1. Qué es un valor atípico y cómo eliminarlo\n",
        "2. Cómo se pueden sesgar los datos\n",
        "3. Cómo mirar la difusión de datos\n",
        "4. Formas básicas de comparar variables, como calificaciones y tiempo de estudio."
      ]
    }
  ]
}